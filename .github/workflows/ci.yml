name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:
  schedule:
    - cron: "0 6 * * 2" # weekly on Tue 06:00 UTC

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        # For now we run tests on the single Python interpreter that matches
        # the vendored binary wheels (cp313). Running the full multi-version
        # matrix requires vendoring matching ABI wheels for each Python
        # version — follow-up work.
        python-version: ["3.13"]

    steps:
      - uses: actions/checkout@v4
        with:
          # Explicitly disable submodule handling to avoid failing
          # `git submodule foreach` cleanup when temporary/removed
          # submodules (like e621_downloader) are present in history.
          submodules: false
          # Fetch full history so other workflow steps can inspect commits
          fetch-depth: 0

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: "pip"

      - name: Install system deps
        run: |
          sudo apt-get update
          sudo apt-get install -y --no-install-recommends ffmpeg libgl1 libsm6 libxext6

      - name: Install dependencies & vendored wheels
        run: |
          python -m pip install --upgrade pip
          pip install flake8 pytest mypy types-PyYAML types-jsonschema numpy onnx
          # Install vendored wheels first (vendored onnxruntime) to ensure compat runtime is available
          python scripts/install_vendored_wheels.py --no-deps || true
          # Do NOT install the project into site-packages for tests.
          # Installing with `pip install -e .` can shadow the source tree and
          # lead to import differences; tests should import the repository
          # source directly via PYTHONPATH set on the test steps.
          echo "Skipping editable install to ensure tests import repo source (PYTHONPATH)"

      - name: Lint with flake8
        run: |
          # Strict linting for production code in nodupe/ directory
          # This enforces the project's .flake8 configuration (79 chars, no errors)
          flake8 nodupe/ --count --show-source --statistics

          # Lenient linting for tests directory (allow some flexibility)
          # Tests can have longer lines for assertions and test data
          flake8 tests/ --count --max-line-length=100 --extend-ignore=E501,F841 --statistics || true

      - name: Type check with mypy (production code only)
        run: |
          # Type check production code with strict settings from pyproject.toml
          # Vendor directory is excluded via config. Production code must pass.
          mypy nodupe/

      - name: Check docstring coverage
        run: |
          pip install interrogate
          # Enforce 100% docstring coverage in CI
          interrogate -vv nodupe/ --fail-under 100

      - name: Test with pytest (fast)
        env:
          # Make tests predictable about progress output
          NO_DUPE_PROGRESS: auto
          # Ensure tests import the repository source first so subpackages
          # like `nodupe.ai` are resolvable during test collection.
          PYTHONPATH: ${{ github.workspace }}
        run: |
          # Run fast tests only (skip slow/integration tests by default)
          # Use new markers from pyproject.toml
          pytest -v -m "not slow and not integration"

  slow-tests:
    name: Slow / Integration tests
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: false
          fetch-depth: 0

      - name: Set up Python 3.13 for slow tests
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"
          cache: "pip"

      - name: Install system deps (slow tests)
        run: |
          sudo apt-get update
          sudo apt-get install -y --no-install-recommends ffmpeg libgl1 libsm6 libxext6

      - name: Install dependencies & vendored wheels (slow tests)
        run: |
          python -m pip install --upgrade pip
          pip install pytest numpy onnx
          python scripts/install_vendored_wheels.py --no-deps || true
          # For slow/integration runs we also prefer importing the repository
          # source by setting PYTHONPATH in the test step; don't install the
          # package into site-packages to avoid masking subpackages.
          echo "Skipping editable install for slow tests to ensure repo source is used"

      - name: Run slow tests
        env:
          NO_DUPE_PROGRESS: auto
          PYTHONPATH: ${{ github.workspace }}
        run: |
          pytest -q -m slow

  vendor-refresh:
    name: Vendor refresh (scheduled)
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' || github.event_name == 'schedule'
    permissions:
      contents: write
      pull-requests: write
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: false
          fetch-depth: 0

      - name: Set up Python 3.13
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Prepare environment
        run: |
          python -m pip install --upgrade pip
          pip install tomli  # fallback for older python envs if needed

      - name: Run vendor script (download latest top-level wheels)
        run: |
          # Download packages and their dependencies into nodupe/vendor/libs
          python scripts/vendor_requirements.py

      - name: Show git status
        run: |
          git status --porcelain=v1 || true

      - name: Commit & push vendor updates (if any)
        id: commit
        run: |
          set -e
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          if ! git diff --quiet -- nodupe/vendor/libs; then
            BRANCH=vendor-refresh/$(date -u +%Y%m%d_%H%M%S)
            git checkout -b "$BRANCH"
            git add nodupe/vendor/libs || true
            git commit -m "chore(vendor): refresh vendored wheels (automated)"
            git push --set-upstream origin "$BRANCH"
            echo "pr_branch=$BRANCH" >>$GITHUB_OUTPUT
          else
            echo "no_changes=true" >>$GITHUB_OUTPUT
          fi

      - name: Create Pull Request
        if: steps.commit.outputs.no_changes != 'true'
        uses: peter-evans/create-pull-request@v5
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          commit-message: "chore(vendor): refresh vendored wheels (automated)"
          title: "Automated vendor refresh: update vendored wheels"
          body: |
            This PR was created automatically by CI to refresh the vendored wheels in `nodupe/vendor/libs`.
            It runs the project's vendoring helper and updates `vendor_manifest.json`.
          base: main
          branch: ${{ steps.commit.outputs.pr_branch }}

      - name: No updates required
        if: steps.commit.outputs.no_changes == 'true'
        run: echo "No vendored updates found."

  validate-vendored-install:
    name: Validate vendored wheel installation
    runs-on: ubuntu-latest
    # keep this small and deterministic: use a single python that matches vendored wheels
    strategy:
      matrix:
        python-version: ["3.13"]

    steps:
      - uses: actions/checkout@v4
        with:
          submodules: false
          fetch-depth: 0

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Prepare environment
        run: |
          python -m pip install --upgrade pip

      - id: install_vendored
        name: Install all vendored wheels into a clean environment (offline)
        # Use the bundled installer helper to install _all_ wheels found in nodupe/vendor/libs.
        run: |
          # If there are no vendored wheels in the checkout then this
          # PR/branch isn't shipping vendored binaries — don't fail the
          # job for that case (this job is primarily a validation for
          # branches that include the vendor files).
          shopt -s nullglob
          files=(nodupe/vendor/libs/*.whl)
          if [ ${#files[@]} -eq 0 ]; then
            echo "No vendored wheels found in nodupe/vendor/libs — skipping validation step"
            echo "no_wheels=true" >> $GITHUB_OUTPUT
            exit 0
          else
            echo "no_wheels=false" >> $GITHUB_OUTPUT
          fi

          # Enforce an offline install to ensure vendored wheels are sufficient
          export PIP_NO_INDEX=1
          python scripts/install_vendored_wheels.py || exit 1

      - name: Smoke import checks
        if: steps.install_vendored.outputs.no_wheels != 'true'
        # Verify a few key packages import successfully after the vendored install.
        run: |
          python - <<'PY'
          import importlib, sys, json
          # The following smoke imports exercise a few vendored wheels to
          # verify pip installed them into the runner environment.
          # Keep this list minimal to keep the job fast.
          pkgs = ['onnxruntime', 'numpy', 'PIL', 'psutil']
          failures = []
          out = {}
          for p in pkgs:
              try:
                  m = importlib.import_module(p)
                  out[p] = getattr(m, '__version__', str(m))
              except Exception as e:
                  failures.append((p, str(e)))
          print('imported:', json.dumps(out))
          if failures:
              print('failures:', failures)
              sys.exit(2)

  doc-sanity:
    name: Docstring & module-size checks
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: false
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Run docstring & module size checker
        run: |
          python -m pip install --upgrade pip
          python scripts/check_docstrings_and_size.py

  docs-build:
    name: Build Sphinx docs
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: false
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Install Sphinx
        run: |
          python -m pip install --upgrade pip
          pip install sphinx

      - name: Build docs
        run: |
          sphinx-build -b html docs/sphinx docs/sphinx/_build || (
            echo "Sphinx build failed" && exit 1
          )
