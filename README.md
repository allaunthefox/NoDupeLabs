# NoDupeLabs

**New to NoDupeLabs?** Check out the [Beginner's Guide](docs/BEGINNERS_GUIDE.md) for step-by-step instructions!

**Important!** NoDupeLabs was written by a combination of LLMs and should not be used on production unless you accept what that implies. It works for me, might not work for you. Might delete everything.

NoDupeLabs is a next-generation, context-aware system for cataloging, deduplicating, and organizing files. It is designed with enhanced safety features and environment-aware performance tuning.

It generates self-describing `meta.json` manifests for every folder so that archives remain readable and verifiable even without the original software.

---

## Overview

NoDupeLabs performs recursive directory scans, identifies unique files using configurable hashing (defaulting to SHA-512), and produces metadata that describes each folder‚Äôs structure, file types, and inferred categories.

Every directory receives a `meta.json` manifest that follows the `nodupe_meta_v1` schema. These manifests are meant to remain valid and machine-readable indefinitely.

---

## Features

### üõ°Ô∏è Enhanced Safety & Integrity
*   **Smart Metadata Updates**: Automatically skips writing `meta.json` if the content hasn't changed, preserving file modification timestamps.
*   **Read-Only Detection**: Proactively checks for read-only directories and files before attempting writes, preventing crash-loops on protected storage.
*   **Verification**: New `verify` command validates checkpoints against the current filesystem state to ensure data integrity before applying changes.

### üöÄ Environment Auto-Tuning
NoDupeLabs automatically detects your deployment environment and optimizes its configuration:
*   **Desktop**: Balances performance with system responsiveness.
*   **NAS**: Optimizes for network I/O and lower CPU availability.
*   **Cloud**: Maximizes throughput for high-speed VM storage.
*   **Container**: Uses conservative defaults for Docker/Kubernetes environments.

### üîç Advanced Detection
*   **Contextual Hashing**: Distinguishes between archived (inside zip/tar) and unarchived copies of the same file.
*   **Expanded MIME Support**: Native detection for modern formats like `.webp`, `.heic`, `.mkv`, and `.json`.
*   **NSFW Classification**: Multi-tier detection system (filename patterns, metadata analysis) to flag potential sensitive content.

### üì¶ Smart Dependency Management
*   **Auto-Install**: Automatically detects and installs optional dependencies (like `psutil`, `tqdm`, `pillow`) at runtime if they are missing.
*   **Graceful Degradation**: If dependencies cannot be installed, the system falls back to standard library implementations without crashing.

---

## Installation

NoDupeLabs is designed to be installed as a Python package.

```bash
# Clone the repository
git clone https://github.com/allaunthefox/NoDupeLabs.git
cd NoDupeLabs

# Install in editable mode
pip install -e .
```

### Minimal/Offline Operation
NoDupeLabs includes vendored copies of essential libraries (`tqdm`, `PyYAML`) in `nodupe/vendor/libs`. If the system Python environment lacks these dependencies, the application will automatically use the bundled versions, ensuring basic functionality works out-of-the-box.

---

## Command Reference

### `scan`
Walks through specified directories, computes hashes, and populates the database.
*   **Incremental Scanning**: Automatically skips re-hashing files that haven't changed (based on size and modification time) since the last scan.
*   **Pre-flight Checks**: Verifies input readability and output writability before starting.

```bash
nodupe scan --root /path/to/data [--root /another/path]
```
*   `--root`: Directory to scan. Can be specified multiple times.

### `plan`
Analyzes the database for duplicates and generates a CSV action plan.
*   **Strategy**: By default, keeps the first file found and marks others for moving to a `.nodupe_duplicates` folder.

```bash
nodupe plan --out plan.csv
```
*   `--out`: Path to save the generated CSV plan.

### `apply`
Executes the actions defined in a plan CSV.
*   **Safety**: Creates a checkpoint file before moving any files, allowing for rollback.

```bash
nodupe apply --plan plan.csv --checkpoint output/checkpoints/chk_01.json [--force]
```
*   `--plan`: Path to the CSV plan generated by `plan`.
*   `--checkpoint`: Path to save the rollback checkpoint.
*   `--force`: Execute changes immediately (disables dry-run mode).

### `verify`
Validates a checkpoint file against the current filesystem state.
*   Ensures that files listed in the checkpoint still exist and haven't been modified before attempting a rollback.

```bash
nodupe verify --checkpoint output/checkpoints/chk_01.json
```

### `rollback`
Undoes a previous `apply` operation using its checkpoint file.
*   Moves files back to their original locations.

```bash
nodupe rollback --checkpoint output/checkpoints/chk_01.json
```

### `similarity`
Tools for finding near-duplicates (e.g., resized images) using vector embeddings.

#### `build`
Creates a similarity index from the database.
```bash
nodupe similarity build --out index.npz [--dim 16]
```

#### `update`
Incrementally updates an existing index with new files from the database.
```bash
nodupe similarity update --index-file index.npz [--rebuild]
```
*   `--index-file`: Path to the existing index.
*   `--rebuild`: Completely rebuild the index from the DB, removing stale entries.

#### `query`
Finds files similar to a target file.
```bash
nodupe similarity query target.jpg --index-file index.npz [-k 5]
```

### `archive`
Utilities for inspecting archive files (zip, tar, etc.) without extracting them.

```bash
nodupe archive list file.zip
nodupe archive extract file.zip --dest /tmp/out
```

### `mount`
Mounts the NoDupeLabs database as a read-only FUSE filesystem (Linux only).
*   Allows browsing files by hash, size, or type.

```bash
nodupe mount /mnt/nodupe
```

---

## Configuration

Configuration is handled via `nodupe.yml`. If it doesn't exist, a default one is generated on the first run. Key settings include:

*   `db_path`: Location of the SQLite database (default: `output/index.db`).
*   `log_dir`: Directory for logs (default: `output/logs`).
*   `parallelism`: Number of threads for scanning (0 = auto).
*   `ignore_patterns`: List of file/folder patterns to skip (e.g., `.git`, `node_modules`).
*   `ai`: Settings for the optional AI backend (ONNX/PyTorch).

```yaml
hash_algo: sha512
dedup_strategy: content_hash
parallelism: 0  # 0 = auto-detect based on environment
dry_run: true
nsfw:
  enabled: false
  threshold: 2
```

---

## Metadata Format

Every directory receives a `meta.json` file describing its contents.

```json
{
  "spec": "nodupe_meta_v1",
  "generated_at": "2025-12-02T12:00:00Z",
  "summary": {
    "files_total": 15,
    "bytes_total": 10485760,
    "categories": {"image": 10, "text": 5},
    "topics": ["vacation", "beach"],
    "keywords": ["2025", "summer"]
  },
  "entries": [
    {
      "name": "photo.jpg",
      "size": 204800,
      "mtime": 1730090400,
      "file_hash": "cf83e1357eefb8bdf1542850d66d8007d620e4050b5715dc83f4a921d36ce9ce47d0d13c5d85f2b0ff8318d2877eec2f63b931bd47417a81a538327af927da3e",
      "hash_algo": "sha512",
      "mime": "image/jpeg",
      "category": "image",
      "subtype": "photo",
      "topic": "vacation"
    }
  ]
}
```

---

## License

NoDupeLabs is distributed under the Apache License 2.0.

```text
SPDX-License-Identifier: Apache-2.0
Copyright (c) 2025 Allaun
```
